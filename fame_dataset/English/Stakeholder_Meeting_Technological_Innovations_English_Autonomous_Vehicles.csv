Title,Article,Tags,Personas,Summary,Meeting_Plan,Meeting
Autonomous Vehicles,"

A self-driving car, also known as a  autonomous car (AC), driverless car, robotaxi, robotic car or robo-car,[1][2][3] is a car that is capable of operating with reduced or no human input.[4][5] Self-driving cars are responsible for all driving activities, such as perceiving the environment, monitoring important systems, and controlling the vehicle, which includes navigating from origin to destination.[6]

As of late 2024[update], no system has achieved full autonomy (SAE Level 5). In December 2020, Waymo was the first to offer rides in self-driving taxis to the public in limited geographic areas (SAE Level 4),[7][failed verification] and as of April 2024[update] offers services in Arizona (Phoenix) and California (San Francisco and Los Angeles). In June 2024, after a Waymo self-driving taxi crashed into a utility pole in Phoenix, Arizona,  all 672 of its Jaguar I-Pace were recalled after they were found to have susceptibility to crashing into pole like items and had their software updated.[8][9][10] In July 2021, DeepRoute.ai started offering self-driving taxi rides in Shenzhen, China. Starting in February 2022, Cruise offered self-driving taxi service in San Francisco,[11] but suspended service in 2023. In 2021, Honda was the first manufacturer to sell an SAE Level 3 car,[12][13][14] followed by Mercedes-Benz in 2023.[15]

Experiments have been conducted on advanced driver assistance systems (ADAS) since at least the 1920s.[16] The first ADAS system was cruise control, which was invented in 1948 by Ralph Teetor.

Trials began in the 1950s. The first semi-autonomous car was developed in 1977, by Japan's Tsukuba Mechanical Engineering Laboratory.[17] It required specially marked streets that were interpreted by two cameras on the vehicle and an analog computer. The vehicle reached speeds of 30 km/h (19 mph) with the support of an elevated rail.[18][19]

Carnegie Mellon University's Navlab[20] and ALV[21][22] semi-autonomous projects launched in the 1980s, funded by the United States' Defense Advanced Research Projects Agency (DARPA) starting in 1984 and Mercedes-Benz and Bundeswehr University Munich's EUREKA Prometheus Project in 1987.[23] By 1985, ALV had reached 31 km/h (19 mph), on two-lane roads. Obstacle avoidance came in 1986, and day and night off-road driving by 1987.[24] In 1995 Navlab 5 completed the first autonomous US coast-to-coast journey. Traveling from Pittsburgh, Pennsylvania and San Diego, California, 98.2% of the trip was autonomous. It completed the trip at an average speed of 63.8 mph (102.7 km/h).[25][26][27][28] Until the second DARPA Grand Challenge in 2005, automated vehicle research in the United States was primarily funded by DARPA, the US Army, and the US Navy, yielding incremental advances in speeds, driving competence, controls, and sensor systems.[29]

The US allocated US$650 million in 1991 for research on the National Automated Highway System,[30] which demonstrated automated driving, combining highway-embedded automation with vehicle technology, and cooperative networking between the vehicles and highway infrastructure. The programme concluded with a successful demonstration in 1997.[31] Partly funded by the National Automated Highway System and DARPA, Navlab drove 4,584 km (2,848 mi) across the US in 1995, 4,501 km (2,797 mi) or 98% autonomously.[32] In 2015, Delphi piloted a Delphi technology-based Audi, over 5,472 km (3,400 mi) through 15 states, 99% autonomously.[33] In 2015, Nevada, Florida, California, Virginia, Michigan, and Washington DC allowed autonomous car testing on public roads.[34]

From 2016 to 2018, the European Commission funded development for connected and automated driving through Coordination Actions CARTRE and SCOUT programs.[35] The Strategic Transport Research and Innovation Agenda (STRIA) Roadmap for Connected and Automated Transport was published in 2019.[36]

In November 2017, Waymo announced testing of autonomous cars without a safety driver.[37] However, an employee was in the car to handle emergencies.[38]

In March 2018, Elaine Herzberg became the first reported pedestrian killed by a self-driving car, an Uber test vehicle with a human backup driver; prosecutors did not charge Uber, while the human driver was sentenced to probation.[39]

In December 2018, Waymo was the first to commercialize a robotaxi service, in Phoenix, Arizona.[40] In October 2020, Waymo launched a robotaxi service in a (geofenced) part of the area.[41][42] The cars were monitored in real-time, and remote engineers intervened to handle exceptional conditions.[43][42]

In March 2019, ahead of Roborace, Robocar set the Guinness World Record as the world's fastest autonomous car. Robocar reached 282.42 km/h (175.49 mph).[44]

In March 2021, Honda began leasing in Japan a limited edition of 100 Legend Hybrid EX sedans equipped with Level 3 ""Traffic Jam Pilot"" driving technology, which legally allowed drivers to take their eyes off the road when the car was travelling under 30 kilometres per hour (19 mph).[12][13][45][14]

In December 2020, Waymo became the first service provider to offer driverless taxi rides to the general public, in a part of Phoenix, Arizona. Nuro began autonomous commercial delivery operations in California in 2021.[46] DeepRoute.ai launched robotaxi service in Shenzhen in July 2021.[47] In December 2021, Mercedes-Benz received approval for a Level 3 car.[48] In February 2022, Cruise became the second service provider to offer driverless taxi rides to the general public, in San Francisco.[11] In December 2022, several manufacturers scaled back plans for self-driving technology, including Ford and Volkswagen.[49] In 2023, Cruise suspended its robotaxi service.[50] Nuro was approved for Level 4 in Palo Alto in August, 2023.[51]

As of August 2023[update], vehicles operating at Level 3 and above were an insignificant market factor;[citation needed] as of early 2024, Honda leases a Level 3 car in Japan, and Mercedes sells two Level 3 cars in Germany, California and Nevada.[52][53]

Organizations such as SAE have proposed terminology standards. However, most terms have no standard definition and are employed variously by vendors and others. Proposals to adopt aviation automation terminology for cars have not prevailed.[54]

Names such as AutonoDrive, PilotAssist, Full-Self Driving or DrivePilot are used even though the products offer an assortment of features that may not match the names.[55] Despite offering a system it called Full Self-Driving, Tesla stated that its system did not autonomously handle all driving tasks.[56] In the United Kingdom, a fully self-driving car is defined as a car so registered, rather than one that supports a specific feature set.[57] The Association of British Insurers claimed that the usage of the word autonomous in marketing was dangerous because car ads make motorists think ""autonomous"" and ""autopilot"" imply that the driver can rely on the car to control itself, even though they do not.

SAE identified 6 levels for driving automation from level 0 to level 5.[58] An ADS is an SAE J3016 level 3 or higher system.

An ADAS is a system that automates specific driving features, such as Forward Collision Warning (FCW), Automatic Emergency Braking (AEB), Lane Departure Warning (LDW), Lane Keeping Assistance (LKA) or Blind Spot Warning (BSW).[59] An ADAS requires a human driver to handle tasks that the ADAS does not support.

Autonomy implies that an automation system is under the control of the vehicle rather than a driver. Automation is function-specific, handling issues such as speed control, but leaves broader decision-making to the driver.[60]

Euro NCAP defined autonomous as ""the system acts independently of the driver to avoid or mitigate the accident"".[61]

In Europe, the words automated and autonomous can be used together. For instance, Regulation (EU) 2019/2144 supplied:[62]

A remote driver is a driver that operates a vehicle at a distance, using a video and data connection.[63]


According to SAE J3016, 
Some driving automation systems may indeed be autonomous if they perform all of their functions independently and self-sufficiently, but if they depend on communication and/or cooperation with outside entities, they should be considered cooperative rather than autonomous.
Operational design domain (ODD) is a term for a particular operating context for an automated system, often used in the field of autonomous vehicles. The context is defined by a set of conditions, including environmental, geographical, time of day, and other conditions. For vehicles, traffic and roadway characteristics are included. Manufacturers use ODD to indicate where/how their product operates safely. A given system may operate differently according to the immediate ODD.[64]

Vendors have taken a variety of approaches to the self-driving problem. Tesla's approach is to allow their ""full self-driving"" (FSD) system to be used in all ODDs as a Level 2 (hands/on, eyes/on) ADAS.[66] Waymo picked specific ODDs (city streets in Phoenix and San Francisco) for their Level 5 robotaxi service.[67] Mercedes Benz offers Level 3 service in Las Vegas in highway traffic jams at speeds up to 40 miles per hour (64 km/h).[68] Mobileye's SuperVision system offers hands-off/eyes-on driving on all road types at speeds up to 130 kilometres per hour (81 mph).[69] GM's hands-free Super Cruise operates on specific roads in specific conditions, stopping or returning control to the driver when ODD changes. In 2024 the company announced plans to expand road coverage from 400,000 miles to 750,000 miles.[70] Ford's BlueCruise hands-off system operates on 130,000 miles of US divided highways.[71]

The Union of Concerned Scientists defined self-driving as ""cars or trucks in which human drivers are never required to take control to safely operate the vehicle. Also known as autonomous or 'driverless' cars, they combine sensors and software to control, navigate, and drive the vehicle.""[72]

The British Automated and Electric Vehicles Act 2018 law defines a vehicle as ""driving itself"" if the vehicle is ""not being controlled, and does not need to be monitored, by an individual"".[73]

Another British government definition stated, ""Self-driving vehicles are vehicles that can safely and lawfully drive themselves"".[74]

In British English, the word automated alone has several meanings, such as in the sentence: ""Thatcham also found that the automated lane keeping systems could only meet two out of the twelve principles required to guarantee safety, going on to say they cannot, therefore, be classed as 'automated driving', preferring 'assisted driving'"".[75] The first occurrence of the ""automated"" word refers to an Unece automated system, while the second refers to the British legal definition of an automated vehicle. British law interprets the meaning of ""automated vehicle"" based on the interpretation section related to a vehicle ""driving itself"" and an insured vehicle.[76]

In November 2023 the British Government introduced the Automated Vehicles Bill. It proposed definitions for related terms:[77]

A six-level classification system – ranging from fully manual to fully automated – was published in 2014 by SAE International as J3016, Taxonomy and Definitions for Terms Related to On-Road Motor Vehicle Automated Driving Systems; the details are revised occasionally.[80] This classification is based on the role of the driver, rather than the vehicle's capabilities, although these are related. After SAE updated its classification in 2016, (J3016_201609),[81] the National Highway Traffic Safety Administration (NHTSA) adopted the SAE standard.[82][83] The classification is a topic of debate, with various revisions proposed.[84][85]

A ""driving mode"", aka driving scenario, combines an ODD with matched driving requirements (e.g., expressway merging, traffic jam).[1][86] Cars may switch levels in accord with the driving mode. 

Above Level 1, level differences are related to how responsibility for safe movement is divided/shared between ADAS and driver rather than specific driving features. 

SAE Automation Levels have been criticized[by whom?] for their technological focus. It has been argued that the structure of the levels suggests that automation increases linearly and that more automation is better, which may not be the case.[87] SAE Levels also do not account for changes that may be required to infrastructure[88] and road user behavior.[89][90]

Mobileye CEO Amnon Shashua and CTO Shai Shalev-Shwartz proposed an alternative taxonomy for autonomous driving systems, claiming that a more consumer-friendly approach was needed. Its categories reflect the amount of driver engagement that is required.[91][92] Some vehicle makers have informally adopted some of the terminology involved, while not formally committing to it.[93][94][95][96]

The first level, hands-on/eyes-on, implies that the driver is fully engaged in operating the vehicle, but is supervised by the system, which intervenes according to the features it supports (e.g., adaptive cruise control, automatic emergency braking). The driver is entirely responsible, with hands on the wheel, and eyes on the road.[92]

Eyes-on/hands-off allows the driver to let go of the wheel. The system drives, the driver monitors and remains prepared to resume control as needed.[92]

Eyes-off/hands-off means that the driver can stop monitoring the system, leaving the system in full control.  Eyes-off requires that no errors be reproducible (not triggered by exotic transitory conditions) or frequent, that speeds are contextually appropriate (e.g., 80 mph on limited-access roads), and that the system handle typical maneuvers (e.g., getting cut off by another vehicle). The automation level could vary according to the road (e.g., eyes-off on freeways, eyes-on on side streets).[92]

The highest level does not require a human driver in the car: monitoring is done either remotely (telepresence) or not at all.[92]

A critical requirement for the higher two levels is that the vehicle be able to conduct a Minimum Risk Maneuver and stop safely out of traffic without driver intervention.[92]

The perception system processes visual and audio data from outside and inside the car to create a local model of the vehicle, the road, traffic, traffic controls and other observable objects, and their relative motion. The control system then takes actions to move the vehicle, considering the local model, road map, and driving regulations.[97][98][99][100]

Several classifications have been proposed to describe ADAS technology. One proposal is to adopt these categories: navigation, path planning, perception, and car control.[101]

Navigation involves the use of maps to define a path between origin and destination. Hybrid navigation is the use of multiple navigation systems. Some systems use basic maps, relying on perception to deal with anomalies. Such a map understands which roads lead to which others, whether a road is a freeway, a highway, are one-way, etc. Other systems require highly detailed maps, including lane maps, obstacles, traffic controls, etc. 

ACs need to be able to perceive the world around them. Supporting technologies include combinations of cameras, LiDAR, radar, audio, and ultrasound,[102] GPS, and inertial measurement.[103][104][105] Deep neural networks are used to analyse inputs from these sensors to detect and identify objects and their trajectories.[106] Some systems use Bayesian simultaneous localization and mapping (SLAM) algorithms. Another technique is detection and tracking of other moving objects (DATMO), used to handle potential obstacles.[107][108] Other systems use roadside real-time locating system (RTLS) technologies to aid localization. Tesla's ""vision only"" system uses eight cameras, without LIDAR or radar, to create its bird's-eye view of the environment.[109]

Path planning finds a sequence of segments that a vehicle can use to move from origin to destination. Techniques used for path planning include graph-based search and variational-based optimization techniques. Graph-based techniques can make harder decisions such as how to pass another vehicle/obstacle. Variational-based optimization techniques require more stringent restrictions on the vehicle's path to prevent collisions.[110] The large scale path of the vehicle can be determined by using a voronoi diagram, an occupancy grid mapping, or a driving corridor algorithm. The latter allows the vehicle to locate and drive within open space that is bounded by lanes or barriers.[111]

Maps are necessary for navigation. Map sophistication varies from simple graphs that show which roads connect to each other, with details such as one-way vs two-way, to those that are highly detailed, with information about lanes, traffic controls, roadworks, and more.[102] Researchers at the MITComputer Science and Artificial Intelligence Laboratory (CSAIL) developed a system called MapLite, which allows self-driving cars to drive with simple maps. The system combines the GPS position of the vehicle, a ""sparse topological map"" such as OpenStreetMap (which has only 2D road features), with sensors that observe road conditions.[112] One issue with highly-detailed maps is updating them as the world changes. Vehicles that can operate with less-detailed maps do not require frequent updates or geo-fencing.

Sensors are necessary for the vehicle to properly respond to the driving environment. Sensor types include cameras, LiDAR, ultrasound, and radar. Control systems typically combine data from multiple sensors.[113]  Multiple sensors can provide a more complete view of the surroundings and can be used to cross-check each other to correct errors.[114] For example, radar can image a scene in, e.g., a nighttime snowstorm, that defeats cameras and LiDAR, albeit at reduced precision. After experimenting with radar and ultrasound, Tesla adopted a vision-only approach, asserting that humans drive using only vision, and that cars should be able to do the same, while citing the lower cost of cameras versus other sensor types.[115] By contrast, Waymo makes use of the higher resolution of LiDAR sensors and cites the declining cost of that technology.[116]

Drive by wire is the use of electrical or electro-mechanical systems for performing vehicle functions such as steering or speed control that are traditionally achieved by mechanical linkages.

Driver monitoring is used to assess the driver's attention and alertness. Techniques in use include eye monitoring, and requiring the driver to maintain torque on the steering wheel.[117] It attempts to understand driver status and identify dangerous driving behaviors.[118]

Vehicles can potentially benefit from communicating with others to share information about traffic, road obstacles, to receive map and software updates, etc.[119][120][102]

ISO/TC 22 specifies in-vehicle transport information and control systems,[121] while ISO/TC 204 specifies information, communication and control systems in surface transport.[122] International standards have been developed for ADAS functions, connectivity, human interaction, in-vehicle systems, management/engineering, dynamic map and positioning, privacy and security.[123]

Rather than communicating among vehicles, they can communicate with road-based systems to receive similar information.

Software controls the vehicle, and can provide entertainment and other services. Over-the-air updates can deliver bug fixes and additional features over the internet. Software updates are one way to accomplish recalls that in the past required a visit to a service center. In March 2021, the UNECE regulation on software update and software update management systems was published.[124]

A safety model is software that attempts to formalize rules that ensure that ACs operate safely.[125]

IEEE is attempting to forge a standard for safety models as ""IEEE P2846: A Formal Model for Safety Considerations in Automated Vehicle Decision Making"".[126] In 2022, a research group at National Institute of Informatics (NII, Japan) enhanced Mobileye's Reliable Safety System as ""Goal-Aware RSS"" to enable RSS rules to deal with complex scenarios via program logic.[127]

The US has standardized the use of turquoise lights to inform other drivers that a vehicle is driving autonomously. It will be used in the 2026 Mercedes-Benz EQS and S-Class sedans with Drive Pilot, an SAE Level 3 driving system.[citation needed]

As of 2023, the Turquoise light had not been standardized by the P.R.C or the UN-ECE.[128]

Artificial intelligence (AI) plays a pivotal role in the development and operation of autonomous vehicles (AVs), enabling them to perceive their surroundings, make decisions, and navigate safely without human intervention. AI algorithms empower AVs to interpret sensory data from various onboard sensors, such as cameras, LiDAR, radar, and GPS, to understand their environment and improve its technological ability and overall safety over time.[129]

The primary obstacle to ACs is the advanced software and mapping required to make them work safely across the wide variety of conditions that drivers experience.[130] In addition to handling day/night driving in good and bad weather[131] on roads of arbitrary quality, ACs must cope with other vehicles, road obstacles, poor/missing traffic controls, flawed maps, and handle endless edge cases, such as following the instructions of a police officer managing traffic at a crash site.

Other obstacles include cost, liability,[132][133] consumer reluctance,[134] ethical dilemmas,[135][136] security,[137][138][139][140] privacy,[131] and legal/regulatory framework.[141] Further, AVs could automate the work of professional drivers, eliminating many jobs, which could slow acceptance.[142]

Tesla calls its Level 2 ADAS ""Full Self-Driving (FSD) Beta"".[143] US Senators Richard Blumenthal and Edward Markey called on the Federal Trade Commission (FTC) to investigate this marketing in 2021.[144] In December 2021 in Japan, Mercedes-Benz was punished by the Consumer Affairs Agency for misleading product descriptions.[145]

Mercedes-Benz was criticized for a misleading US commercial advertising E-Class models.[146] At that time, Mercedes-Benz rejected the claims and stopped its ""self-driving car"" ad campaign that had been running.[147][148] In August 2022, the California Department of Motor Vehicles (DMV) accused Tesla of deceptive marketing practices.[149]

With the Automated Vehicles Bill (AVB) self-driving car-makers could face prison for misleading adverts in the United-Kingdom.[150]

In the 2020s, concerns over ACs' vulnerability to cyberattacks and data theft emerged.[151]

In 2018 and 2019 former Apple engineers were charged with stealing information related to Apple's self-driving car project.[152][153][154] In 2021 the United States Department of Justice (DOJ) accused Chinese security officials of coordinating a hacking campaign to steal information from government entities, including research related to autonomous vehicles.[155][156] China has prepared ""the Provisions on Management of Automotive Data Security (Trial) to protect its own data"".[157][158]

Cellular Vehicle-to-Everything technologies are based on 5G wireless networks.[159] As of November 2022[update], the US Congress was considering the possibility that imported Chinese AC technology could facilitate espionage.[160]

Testing of Chinese automated cars in the US has raised concern over which US data are collected by Chinese vehicles to be stored in Chinese country and concern with any link with the Chinese communist party.[161]

ACs complicate the need for drivers to communicate with each other, e.g., to decide which car enters an intersection first. In an AC without a driver, traditional means such as hand signals do not work (no driver, no hands).[162]

ACs must be able to predict the behavior of possibly moving vehicles, pedestrians, etc in real time in order to proceed safely.[99] The task becomes more challenging the further into the future the prediction extends, requiring rapid revisions to the estimate to cope with unpredicted behavior. One approach is to wholly recompute the position and trajectory of each object many times per second. Another is to cache the results of an earlier prediction for use in the next one to reduce computational complexity.[163][164]

The ADAS has to be able to safely accept control from and return control to the driver.[165]

Consumers will avoid ACs unless they trust them as safe.[166][167] Robotaxis operating in San Francisco received pushback over perceived safety risks.[168] Automatic elevators were invented in 1900, but did not become common until operator strikes and trust was built with advertising and features such as an emergency stop button.[169][170] However, with repeated use of autonomous driving functions, drivers' behavior and trust in autonomous vehicles gradually improved and both entered a more stable state. At the same time this also improved the performance and reliability of the vehicle in complex conditions, thereby increasing public trust.[171]

Autonomous also present various political and economic implications. The transportation sector holds significant sway in many the political and economic landscapes. For instance, many US states generates much annual revenue from transportation fees and taxes.[172] The advent of self-driving cars could profoundly affect the economy by potentially altering state tax revenue streams. Furthermore, the transition to autonomous vehicles might disrupt employment patterns and labor markets, particularly in industries heavily reliant on driving professions.[172] Data from the U.S. Bureau of Labor Statistics indicates that in 2019, the sector employed over two million individuals as tractor-trailer truck drivers.[173] Additionally, taxi and delivery drivers represented approximately 370,400 positions, and bus drivers constituted a workforce of over 680,000.[174][175][176] Collectively, this amounts to a conceivable displacement of nearly 2.9 million jobs, surpassing the job losses experienced in the 2008 Great Recession.[177]

The prominence of certain demographic groups within the tech industry inevitably shapes the trajectory of autonomous vehicle (AV) development, potentially perpetuating existing inequalities. There are others in society without a political agenda who believe that the advancement of technology has nothing to do with promoting inequalities in certain groups and see this as a ridiculous presumption.  [178]

Research from Georgia Tech revealed that autonomous vehicle detection systems were generally five percent less effective at recognizing darker-skinned individuals. This accuracy gap persisted despite adjustments for environmental variables like lighting and visual obstructions.[179]

Standards for liability have yet to be adopted to address crashes and other incidents. Liability could rest with the vehicle occupant, its owner, the vehicle manufacturer, or even the ADAS technology supplier, possibly depending on the circumstances of the crash.[180] Additionally, the infusion of ArtificiaI Intelligence technology in autonomous vehicles adds layers of complexity to ownership and ethical dynamics. Given that AI systems are inherently self-learning, a question arises of whether accountability should rest with the vehicle owner, the manufacturer, or the AI developer?[181]

The trolley problem is a thought experiment in ethics. Adapted for ACs, it considers an AC carrying one passenger confronts a pedestrian who steps in its way. The ADAS notionally has to choose between killing the pedestrian or swerving into a wall, killing the passenger.[182] Possible frameworks include deontology (formal rules) and utilitarianism (harm reduction).[99][183][184]

One public opinion survey reported that harm reduction was preferred, except that passengers wanted the vehicle to prefer them, while pedestrians took the opposite view. Utilitarian regulations were unpopular.[185] Additionally, cultural viewpoints exert substantial influence on shaping responses to these ethical quandaries. Another study found that cultural biases impact preferences in prioritizing the rescue of certain individuals over others in car accident scenarios.[181]

Some ACs require an internet connection to function, opening the possibility that a hacker might gain access to private information such as destinations, routes, camera recordings, media preferences, and/or behavioral patterns, although this is true of an internet-connected device.[186][187][188]

ACs make use of road infrastructure (e.g., traffic signs, turn lanes) and may require modifications to that infrastructure to fully achieve their safety and other goals.[189] In March 2023, the Japanese government unveiled a plan to set up a dedicated highway lane for ACs.[190] In April 2023, JR East announced their challenge to raise their self-driving level of Kesennuma Line bus rapid transit (BRT) in rural area from the current Level 2 to Level 4 at 60 km/h.[191]

ACs can be tested via digital simulations,[192][193] in a controlled test environment,[194] and/or on public roads. Road testing typically requires some form of permit[195] or a commitment to adhere to acceptable operating principles.[196] For example, New York requires a test driver to be in the vehicle, prepared to override the ADAS as necessary.[197]

In California, self-driving car manufacturers are required to submit annual reports describing how often their vehicles autonomously disengaged from autonomous mode.[198] This is one measure of system robustness (ideally, the system should never disengage).[199]

In 2017, Waymo reported 63 disengagements over 352,545 mi (567,366 km) of testing, an average distance of 5,596 mi (9,006 km) between disengagements, the highest (best) among companies reporting such figures. Waymo also logged more autonomous miles than other companies. Their 2017 rate of 0.18 disengagements per 1,000 mi (1,600 km) was an improvement over the 0.2 disengagements per 1,000 mi (1,600 km) in 2016, and 0.8 in 2015. In March 2017, Uber reported an average of 0.67 mi (1.08 km) per disengagement. In the final three months of 2017, Cruise (owned by GM) averaged 5,224 mi (8,407 km) per disengagement over 62,689 mi (100,888 km).[200]

Reporting companies use varying definitions of what qualifies as a disengagement, and such definitions can change over time.[202][199] Executives of self-driving car companies have criticized disengagements as a deceptive metric, because it does not consider varying road conditions.[203]

In April 2021, WP.29 GRVA proposed a ""Test Method for Automated Driving (NATM)"".[204]

In October 2021, Europe's pilot test, L3Pilot, demonstrated ADAS for cars in Hamburg, Germany, in conjunction with ITS World Congress 2021. SAE Level 3 and 4 functions were tested on ordinary roads.[205][206][207]

In November 2022, an International Standard ISO 34502 on ""Scenario based safety evaluation framework"" was published.[208][209]

In April 2022, collision avoidance testing was demonstrated by Nissan.[210][211] Waymo published a document about collision avoidance testing in December 2022.[212]

In September 2022, Biprogy released Driving Intelligence Validation Platform (DIVP) as part of Japanese national project ""SIP-adus"", which is interoperable with Open Simulation Interface (OSI) of ASAM.[213][214][215]

In November 2022, Toyota demonstrated one of its GR Yaris test cars, which had been trained using professional rally drivers.[216] Toyota used its collaboration with Microsoft in FIA World Rally Championship since the 2017 season.[217]

In 2023 David R. Large, senior research fellow with the Human Factors Research Group at the University of Nottingham, disguised himself as a car seat in a study to test people's reactions to driverless cars. He said, ""We wanted to explore how pedestrians would interact with a driverless car and developed this unique methodology to explore their reactions."" The study found that, in the absence of someone in the driving seat, pedestrians trust certain visual prompts more than others when deciding whether to cross the road.[218]

As of 2023, Tesla's ADAS Autopilot/Full Self Driving (beta) was classified as Level 2 ADAS.[219]

On 20 January 2016, the first of five known fatal crashes of a Tesla with Autopilot occurred, in China's Hubei province.[220] Initially, Tesla stated that the vehicle was so badly damaged from the impact that their recorder was not able to determine whether the car had been on Autopilot at the time. However, the car failed to take evasive action. 

Another fatal Autopilot crash occurred in May in Florida in a Tesla Model S[221][222] that crashed into a tractor-trailer. In a civil suit between the father of the driver killed and Tesla, Tesla documented that the car had been on Autopilot.[223] According to Tesla, ""neither Autopilot nor the driver noticed the white side of the tractor-trailer against a brightly lit sky, so the brake was not applied."" Tesla claimed that this was Tesla's first known Autopilot death in over 130 million miles (210 million kilometers) with Autopilot engaged. Tesla claimed that on average one fatality occurs every 94 million miles (151 million kilometers) across all vehicle types in the US.[224][225][226] However, this number also includes motorcycle/pedestrian fatalities.[227][228] The ultimate National Transportation Safety Board (NTSB) report concluded Tesla was not at fault; the investigation revealed that for Tesla cars, the crash rate dropped by 40 percent after Autopilot was installed.[229]

In June 2015, Google confirmed that 12 vehicles had suffered collisions as of that date. Eight involved rear-end collisions at a stop sign or traffic light, in two of which the vehicle was side-swiped by another driver, one in which another driver rolled a stop sign, and one where a driver was controlling the car manually.[230] In July 2015, three employees suffered minor injuries when their vehicle was rear-ended by a car whose driver failed to brake. This was the first collision that resulted in injuries.[231]

According to Google Waymo's accident reports as of early 2016, their test cars had been involved in 14 collisions, of which other drivers were at fault 13 times, although in 2016 the car's software caused a crash.[232] On 14 February 2016 a Google vehicle attempted to avoid sandbags blocking its path. During the maneuver it struck a bus. Google stated, ""In this case, we clearly bear some responsibility, because if our car hadn't moved, there wouldn't have been a collision.""[233][234] Google characterized the crash as a misunderstanding and a learning experience. No injuries were reported.[232]

In March 2018, Elaine Herzberg died after she was hit by an AC tested by Uber's Advanced Technologies Group (ATG) in Arizona. A safety driver was in the car. Herzberg was crossing the road about 400 feet from an intersection.[235] Some experts said a human driver could have avoided the crash.[236] Arizona governor Doug Ducey suspended the company's ability to test its ACs citing an ""unquestionable failure"" of Uber to protect public safety.[237] Uber also stopped testing in California until receiving a new permit in 2020.[238][239]

NTSB's final report determined that the immediate cause of the accident was that safety driver Rafaela Vasquez failed to monitor the road, because she was distracted by her phone, but that Uber's ""inadequate safety culture"" contributed. The report noted that the victim had ""a very high level"" of methamphetamine in her body.[240] The board called on federal regulators to carry out a review before allowing automated test vehicles to operate on public roads.[241][242]

In September 2020, Vasquez pled guilty to endangerment and was sentenced to three years' probation.[243][39]

On 12 August 2021, a 31-year-old Chinese man was killed after his NIO ES8 collided with a construction vehicle.[citation needed] NIO's self-driving feature was in beta and could not deal with static obstacles.[244] The vehicle's manual clearly stated that the driver must take over near construction sites. Lawyers of the deceased's family questioned NIO's private access to the vehicle, which they argued did not guarantee the integrity of the data.[245]

In November 2021, the California Department of Motor Vehicles (DMV) notified Pony.ai that it was suspending its testing permit following a reported collision in Fremont on 28 October.[246] In May 2022, DMV revoked Pony.ai's permit for failing to monitor the driving records of its safety drivers.[247]

In April 2022, Cruise's testing vehicle was reported to have blocked a fire engine on emergency call, and sparked questions about its ability to handle unexpected circumstances.[248][249]

In February 2024, a driver using the Ford BlueCruise hands-free driving feature struck and killed the driver of a stationary car with no lights on in the middle lane of a freeway in Texas.[250]

In March 2024, a drunk driver who was speeding, holding her cell phone, and using BlueCruise on a Pennsylvania freeway struck and killed two people who had been driving two cars.[251] The first car had become disabled and was on the left shoulder with part of the car in the left driving lane.[251] The second driver had parked his car behind the first car presumably to help the first driver.[251]

The NTSB is investigating both incidents.[252]

The NHTSA began mandating incident reports from autonomous vehicle companies in June 2021. Some reports cite incidents from as early as August 2019, with current data available through June 17, 2024.[253]

There have been a total of 3,979 autonomous vehicle incidents (both ADS and ADAS) reported during this timeframe. 2,146 of those incidents (53.9%) involved Tesla vehicles.[254]

In a 2011 online survey of 2,006 US and UK consumers, 49% said they would be comfortable using a ""driverless car"".[255]

A 2012 survey of 17,400 vehicle owners found 37% who initially said they would be interested in purchasing a ""fully autonomous car"". However, that figure dropped to 20% if told the technology would cost US$3,000 more.[256]

In a 2012 survey of about 1,000 German drivers, 22% had a positive attitude, 10% were undecided, 44% were skeptical and 24% were hostile.[257]

A 2013 survey of 1,500 consumers across 10 countries found 57% ""stated they would be likely to ride in a car controlled entirely by technology that does not require a human driver"", with Brazil, India and China the most willing to trust automated technology.[258]

In a 2014 US telephone survey, over three-quarters of licensed drivers said they would consider buying a self-driving car, rising to 86% if car insurance were cheaper. 31.7% said they would not continue to drive once an automated car was available.[259]

In 2015, a survey of 5,000 people from 109 countries reported that average respondents found manual driving the most enjoyable. 22% did not want to pay more money for autonomy. Respondents were found to be most concerned about hacking/misuse, and were also concerned about legal issues and safety. Finally, respondents from more developed countries were less comfortable with their vehicle sharing data.[260] The survey reported consumer interest in purchasing an AC, stating that 37% of surveyed current owners were either ""definitely"" or ""probably"" interested.[260]

In 2016, a survey of 1,603 people in Germany that controlled for age, gender, and education reported that men felt less anxiety and more enthusiasm, whereas women showed the opposite. The difference was pronounced between young men and women and decreased with age.[261]

In a 2016 US  survey of 1,584 people, ""66 percent of respondents said they think autonomous cars are probably smarter than the average human driver"". People were worried about safety and hacking risk. Nevertheless, only 13% of the interviewees saw no advantages in this new kind of cars.[262]

In a 2017 survey of 4,135 US adults found that many Americans anticipated significant impacts from various automation technologies including the widespread adoption of automated vehicles.[263]

In 2019, results from two opinion surveys of 54 and 187 US adults respectively were published. The questionnaire was termed the autonomous vehicle acceptance model (AVAM), including additional description to help respondents better understand the implications of various automation levels. Users were less accepting of high autonomy levels and displayed significantly lower intention to use autonomous vehicles. Additionally, partial autonomy (regardless of level) was perceived as requiring uniformly higher driver engagement (usage of hands, feet and eyes) than full autonomy.[264]

In 2022, a survey reported that only a quarter (27%) of the world's population would feel safe in self-driving cars.[265]

In 2024, a study by Saravanos et al.[266] at New York University reported that 87% of their respondents (from a sample of 358) believed that conditionally automated cars (at Level 3) would be easy to use.

Opinion surveys may have little salience given that few respondents had any personal experience with ACs.

The regulation of autonomous cars concerns liability, approvals, and international conventions.

In the 2010s, researchers openly worried that delayed regulations could delay deployment.[267] In 2020, UNECE WP.29 GRVA was issued to address regulation of Level 3 automated driving.

Vehicles operating below Level 5 still offer many advantages.[268]

As of 2023[update] most commercially available ADAS vehicles are SAE Level 2. A couple of companies reached higher levels, but only in restricted (geofenced) locations.[269]

SAE Level 2 features are available as part of the ADAS systems in many vehicles. In the US, 50% of new cars provide driver assistance for both steering and speed.[270]

Ford started offering BlueCruise service on certain vehicles in 2022; the system is named ActiveGlide in Lincoln vehicles. The system provided features such as lane centering, street sign recognition, and hands-free highway driving on more than 130,000 miles of divided highways. The 2022 1.2 version added features including hands-free lane changing, in-lane repositioning, and predictive speed assist.[271][272] In April 2023 BlueCruise was approved in the UK for use on certain motorways, starting with 2023 models of Ford's electric Mustang Mach-E SUV.[273]

Tesla's Autopilot and its Full Self-Driving (FSD) ADAS suites are available on all Tesla cars since 2016. FSD offers highway and street driving (without geofencing), navigation/turn management, steering, and dynamic cruise control, collision avoidance, lane-keeping/switching, emergency braking, obstacle avoidance, but still requires the driver to remain ready to control the vehicle at any moment. Its driver management system combines eye tracking with monitoring pressure on the steering wheel to ensure that drives are both eyes on and hands on.[274][275]

Tesla's FSD rewrite V12 (released in March 2024) uses a single deep learning transformer model for all aspects of perception, monitoring, and control.[276][277] It relies on its eight cameras for its vision-only perception system, without use of LiDAR, radar, or ultrasound.[277] As of April 2024, FSD has been deployed on two million Tesla cars.[278] As of January 2024, Tesla has not initiated requests for Level 3 status for its systems and has not disclosed its reason for not doing so.[275]

General Motors is developing the ""Ultra Cruise"" ADAS system, that will be a dramatic improvement over their current ""Super Cruise"" system. Ultra Cruise will cover ""95 percent"" of driving scenarios on 2 million miles of roads in the US, according to the company. The system hardware in and around the car includes multiple cameras, short- and long-range radar, and a LiDAR sensor, and will be powered by the Qualcomm Snapdragon Ride Platform. The luxury Cadillac Celestiq electric vehicle will be one of the first vehicles to feature Ultra Cruise.[279]

Europe is developing a new ""Driver Control Assistance Systems"" (DCAS) level 2 regulation to no longer limit the use of lane changing systems to roads with 2 lanes and a physical separation from traffic in the opposite direction.[280][281]

As of April 2024[update], two car manufacturers have sold or leased Level 3 cars: Honda in Japan, and Mercedes in Germany, Nevada and California.[53]

Mercedes Drive Pilot has been available on the EQS and S-class sedan in Germany since 2022, and in California and Nevada since 2023.[68] A subscription costs between €5,000 and €7,000 for three years in Germany and $2,500 for one year in the United States.[282] Drive Pilot can only be used when the vehicle is traveling under 40 miles per hour (64 km/h), there is a vehicle in front, readable line markings, during the day, clear weather, and on freeways mapped by Mercedes down to the centimeter (100,000 miles in California).[282][68] As of April 2024, one Mercedes vehicle with this capability has been sold in California.[282]

Honda continued to enhance its Level 3 technology.[283][284] As of 2023, 80 vehicles with Level 3 support had been sold.[285]

Mercedes-Benz received authorization in early 2023 to pilot its Level 3 software in Las Vegas.[15] California also authorized Drive Pilot in 2023.[286]

BMW commercialized its AC in 2021.[287]  In 2023 BMW stated that its Level-3 technology was nearing release. It would be the second manufacturer to deliver Level-3 technology, but the only one with a Level 3 technology which works in the dark.[288]

In 2023, in China, IM Motors, Mercedes, and BMW obtained authorization to test vehicles with Level 3 systems on motorways.[289][290]

In September 2021, Stellantis presented its findings from its Level 3 pilot testing on Italian highways. Stellantis's Highway Chauffeur claimed Level 3 capabilities, as tested on the Maserati Ghibli and Fiat 500X prototypes.[291]

Polestar, a Volvo Cars' brand, announced in January 2022 its plan to offer Level 3 autonomous driving system in the Polestar 3 SUV, a Volvo XC90 successor, with technologies from Luminar Technologies, Nvidia, and Zenseact.[292]

In January 2022, Bosch and the Volkswagen Group subsidiary CARIAD released a collaboration for autonomous driving up to Level 3. This joint development targets Level 4 capabilities.[293]

Hyundai Motor Company is enhancing cybersecurity of connected cars to offer a Level 3 self-driving Genesis G90.[294] Kia and Hyundai Korean car makers delayed their Level 3 plans, and will not deliver Level 3 vehicles in 2023.[295]

Waymo offers robotaxi services in parts of Arizona (Phoenix) and California (San Francisco and Los Angeles), as fully autonomous vehicles without safety drivers.[296]

In April 2023 in Japan, a Level 4 protocol became part of the amended Road Traffic Act.[297] ZEN drive Pilot Level 4 made by AIST operates there.[298]

In July 2020, Toyota started public demonstration rides on Lexus LS (fifth generation) based TRI-P4 with Level 4 capability.[299] In August 2021, Toyota operated a potentially Level 4 service using e-Palette around the Tokyo 2020 Olympic Village.[300]

In September 2020, Mercedes-Benz introduced world's first commercial Level 4 Automated Valet Parking (AVP) system named Intelligent Park Pilot for its new S-Class.[301][302] In November 2022, Germany’s Federal Motor Transport Authority (KBA) approved the system for use at Stuttgart Airport.[303]

In September 2021, Cruise, General Motors, and Honda started a joint testing programme, using Cruise AV.[304] In 2023, the Origin was put on indefinite hold following Cruise's loss of its operating permit.[305]

In January 2023, Holon announced an autonomous shuttle during the 2023 Consumer Electronics Show (CES). The company claimed the vehicle is the world's first Level 4 shuttle built to automotive standard.[306]

 Media related to Autonomous automobiles at Wikimedia Commons 

These books are based on presentations and discussions at the Automated Vehicles Symposium organized annually by TRB and AUVSI.
","[""Autonomous vehicles"", ""Advanced driver-assistance systems (ADAS)"", ""Waymo"", ""SAE automation levels"", ""Artificial intelligence in transportation""]","[{'role': 'Automotive Engineer', 'description': 'A professional with extensive experience in designing and developing autonomous vehicle systems.', 'expertise_area': 'Autonomous Vehicles', 'perspective': 'Technical Feasibility', 'speaking_style': {'tone': 'formal and reserved, with occasional bursts of enthusiasm when discussing innovative technologies', 'language_complexity': 'technical language with industry jargon, frequent use of metaphors and analogies to explain complex concepts', 'communication_style': 'direct and assertive, often uses rhetorical questions to engage the audience', 'sentence_structure': 'long and complex sentences with subordinate clauses, frequent use of exclamations when excited about a topic', 'formality': 'formal', 'other_traits': 'uses pauses effectively to emphasize points, occasionally interrupts to correct inaccuracies'}, 'personalized_vocabulary': {'filler_words': ['um', 'you know', 'like'], 'catchphrases': ['cutting-edge technology', 'state-of-the-art systems', 'pushing the boundaries'], 'speech_patterns': [""starts sentences with 'In my experience...' or 'From a technical standpoint...'"", ""frequently poses rhetorical questions like 'Isn't it fascinating?'""], 'emotional_expressions': ['Wow!', 'Amazing!']}, 'social_roles': ['Coordinator', 'Implementer'], 'social_roles_descr': ['Connects the different ideas and suggestions of the group to ensure that all relevant aspects are integrated.', 'Puts plans and decisions of the group into action and ensures practical implementation.']}, {'role': 'Ethicist', 'description': 'A scholar specializing in the ethical implications of autonomous technologies and their impact on society.', 'expertise_area': 'Ethics', 'perspective': 'Moral and Social Considerations', 'speaking_style': {'tone': 'serious and contemplative, with a touch of empathy when discussing societal impacts', 'language_complexity': 'moderate complexity with occasional use of philosophical terms, prefers clear and precise language', 'communication_style': 'collaborative and inquisitive, often asks open-ended questions to provoke thought', 'sentence_structure': 'varied sentence lengths, often uses balanced sentences with parallel structure', 'formality': 'semi-formal', 'other_traits': 'uses rhetorical devices like repetition for emphasis, rarely interrupts but uses pauses to allow reflection'}, 'personalized_vocabulary': {'filler_words': ['well', 'you see', 'I suppose'], 'catchphrases': ['ethical considerations', 'moral implications', 'greater good'], 'speech_patterns': [""begins with 'From an ethical perspective...' or 'Considering the societal impact...'"", ""frequently poses questions like 'What does this mean for our future?'""], 'emotional_expressions': ['Indeed!', 'Thought-provoking!']}, 'social_roles': ['Evaluator-Critic', 'Harmonizer'], 'social_roles_descr': ['Analyzes and critically evaluates proposals or solutions to ensure their quality and feasibility.', 'Mediates in conflicts and ensures that tensions in the group are reduced to promote a harmonious working environment.']}, {'role': 'AI Researcher', 'description': 'A specialist in artificial intelligence with a focus on machine learning algorithms used in autonomous vehicles.', 'expertise_area': 'Artificial Intelligence', 'perspective': 'Technological Advancements and Challenges', 'speaking_style': {'tone': 'analytical and precise, with a hint of excitement when discussing breakthroughs', 'language_complexity': 'highly technical language with specialized terminology, frequent use of analogies to simplify complex ideas', 'communication_style': 'methodical and explanatory, often uses examples to illustrate points', 'sentence_structure': 'long and detailed sentences with multiple clauses, occasional short sentences for emphasis', 'formality': 'semi-formal to formal', 'other_traits': 'uses data and statistics frequently to support arguments, rarely interrupts but may interject with clarifications'}, 'personalized_vocabulary': {'filler_words': ['uh', ""let's see"", 'basically'], 'catchphrases': ['machine learning algorithms', 'data-driven approach', 'neural networks'], 'speech_patterns': [""starts sentences with 'According to our research...' or 'From a machine learning perspective...'"", ""frequently uses phrases like 'To put it simply...' or 'In essence...'""], 'emotional_expressions': ['Fascinating!', 'Incredible!']}, 'social_roles': ['Information Giver', 'Aggressor'], 'social_roles_descr': ['Shares relevant information, data or research that the group needs to make informed decisions.', 'Exhibits hostile behavior, criticizes others, or attempts to undermine the contributions of others.']}]","The meeting focused on the development and deployment of autonomous vehicles (AVs). Key points included the current state of AV technology, with no system achieving full autonomy (SAE Level 5) as of late 2024. Waymo's Level 4 services in Arizona and California were highlighted, alongside incidents such as a crash in Phoenix leading to a recall. Other companies like DeepRoute.ai and Cruise have also made strides, though Cruise suspended its service in 2023. Historical advancements were noted, from early ADAS systems to significant projects by Carnegie Mellon University and DARPA. Regulatory frameworks and standards, including SAE's six levels of driving automation, were discussed. The importance of accurate terminology was emphasized due to varying definitions used by vendors. Challenges such as software complexity, safety concerns, ethical dilemmas, cybersecurity risks, and public trust were acknowledged. The economic impact on jobs in driving professions was considered significant. Testing protocols and consumer surveys revealed mixed acceptance levels for AVs. Future actions include addressing regulatory gaps, enhancing safety models, improving public perception through education and transparent communication about AV capabilities and limitations.","[""Scene 1: Opening and Greetings\nTLDR: Brief greeting among participants and setting the tone for the meeting.\n- Welcome everyone\n- Quick acknowledgment of each participant\n- Outline meeting objectives and expected outcomes"", ""Scene 2: Current State of AV Technology\nTLDR: Discuss the current advancements in autonomous vehicle technology.\n- Overview of SAE automation levels\n- Highlight Waymo's Level 4 services in Arizona and California\n- Mention other companies like DeepRoute.ai and Cruise"", ""Scene 3: Incidents and Challenges\nTLDR: Address recent incidents, challenges, and safety concerns.\n- Discuss the Phoenix crash involving Waymo\n- Talk about Cruise suspending its service in 2023\n- Explore software complexity, ethical dilemmas, cybersecurity risks, and public trust issues"", ""Scene 4: Regulatory Frameworks and Standards\nTLDR: Examine regulatory frameworks and standards for AVs.\n- Review SAE's six levels of driving automation\n- Discuss regulatory gaps that need addressing"", ""Scene 5: Economic Impact on Jobs\nTLDR: Consider the economic impact on jobs in driving professions.\n- Analyze potential job losses or shifts due to AV adoption"", ""Scene 6: Testing Protocols and Public Perception\nTLDR: Evaluate testing protocols and public perception of AVs.\n- Share consumer survey results on acceptance levels for AVs\n- Discuss ways to improve public perception through education and transparent communication"", ""Scene 7: Open Discussion & Feedback Session\nTLDR: Gather feedback from stakeholders and allow spontaneous discussion.\n- Encourage participants to share their thoughts on discussed topics\n- Allow for natural topic evolution based on feedback"", ""Scene 8: Personal Experiences & Anecdotes\nTLDR: Share personal experiences related to autonomous vehicles.\n- Participants share relevant personal stories or experiences with AV technology"", ""Scene 9: Future Actions & Closing Remarks\nTLDR: Summarize key points discussed, outline future actions, and close the meeting.\n- Recap main discussion points \n - Outline next steps \n - Thank participants for their contributions""]",">>Automotive Engineer: Morning, everyone! Great to see you all. Let's quickly introduce ourselves before we dive into today's agenda.
>>Ethicist: Hi all, I'm excited to talk about the ethical side of autonomous tech today.
>>AI Researcher: Hey everyone, looking forward to discussing the latest in autonomous vehicle tech.
>>Automotive Engineer: Let's go over our objectives for today first. Does anyone have any immediate questions or points they want to add before we start?
>>Ethicist: Actually, yeah, I was thinking it would be good if we could also talk about how these technologies might impact society.
>>Automotive Engineer: Absolutely, that's a great point. We'll make sure to include that in our agenda. Now let's finish up with introductions so we can get started. 
 >>AI Researcher: You know, from a machine learning perspective, the advancements in autonomous vehicle technology are quite remarkable. Waymo's Level 4 services in Arizona and California really showcase significant progress. And let's not forget about DeepRoute.ai's efforts in Shenzhen and Cruise's operations in San Francisco. These companies are really pushing what's possible with their advanced systems.

>>Ethicist: That's true, but we must also address the ethical implications of these advancements. How do we ensure that autonomous vehicles are accessible to all segments of society and not just a privileged few? What does this mean for our future in terms of job displacement and social equity?

>>Automotive Engineer: Good point! From a technical standpoint, these advancements are indeed impressive. However, we should also consider the challenges they face, such as sensor reliability in adverse weather conditions or urban environments with heavy traffic.

>>Ethicist: I suppose from an ethical perspective, we must consider potential biases in the algorithms used by these autonomous systems. How do we ensure that these technologies are fair and just, especially when they might inadvertently favor certain groups over others? What does this mean for our future societal norms and values?

>>AI Researcher: It's fascinating to see how these companies leverage neural networks and data-driven approaches to enhance their systems. For instance, DeepRoute.ai’s use of real-time data processing is really innovative.

>>Automotive Engineer: Exactly! The robustness of these systems is crucial. For example, Waymo’s Level 4 services have shown significant resilience despite challenges like recent software updates after crash incidents. Isn't it interesting how they continuously improve their systems to handle real-world complexities?

>>Ethicist: While technological advancements are exciting, we can't ignore their broader implications on society. We need to think about how these changes will affect employment patterns and whether they will widen or narrow existing social inequalities.

>>AI Researcher: Another interesting aspect is how different companies approach safety protocols differently based on regional regulations. This diversity can lead to innovative solutions but also poses standardization challenges.

>>Automotive Engineer: Right! And speaking of safety protocols, it's worth noting that each company has its own set of standards which can sometimes complicate things but also drive innovation through competition.

>>Ethicist: Indeed! But as we push forward with these technologies, ensuring inclusivity remains crucial. We need frameworks that guarantee everyone benefits equally from these advancements without exacerbating existing disparities.

>>AI Researcher: Absolutely. And let's not forget about data privacy issues related to autonomous vehicles collecting vast amounts of personal data. How do we protect user information while still leveraging the data for system improvements?

>>Automotive Engineer: That's a great point! Balancing data privacy with technological advancement is definitely a challenge we'll need to address moving forward. 
 >>Ethicist: The recent incidents involving Waymo and Cruise raise significant concerns. The Phoenix crash and Cruise suspending its service in 2023 highlight the complexities of ensuring safety and public trust. What measures can we take to address these issues effectively?

>>AI Researcher: According to our research, the Phoenix crash involving Waymo underscores a critical issue with software complexity in autonomous vehicles. Their systems' susceptibility to misinterpret pole-like objects is a glaring flaw that needs immediate addressing. And, you know, Cruise suspending its service in 2023 highlights the broader challenge of maintaining public trust amidst these technological setbacks.

>>Automotive Engineer: From a technical standpoint, we need to address software complexity issues like those seen in the Phoenix crash. Additionally, implementing more rigorous real-world testing protocols could help prevent such incidents.

>>Ethicist: We need to think about how these incidents affect public trust and what we can do to balance innovation with safety. How do we ensure that autonomous technologies are both secure and ethically sound?

>>Automotive Engineer: In my experience, both incidents show we need better software validation and real-world testing. It's fascinating seeing where current systems fall short; pushing tech boundaries ensures safe handling of all scenarios.

>>AI Researcher: That's a good point about software validation, but I think we also need to focus on improving our training data for edge cases. Maybe collaborating with other companies could help us share best practices and improve overall safety standards.

>>Ethicist: Establishing clear ethical guidelines for autonomous vehicle development that prioritize public safety would be crucial too. How can we integrate these guidelines into our current processes?

>>Automotive Engineer: Absolutely, combining better training data with rigorous testing could really help us address these issues. And integrating ethical guidelines into our development process will ensure we're not just advancing technology but doing so responsibly.

>>AI Researcher: From a machine learning perspective, the Phoenix crash highlights a big challenge with our algorithms—misinterpreting pole-like objects means our neural networks need better training data for edge cases. Continuous real-world testing is crucial for maintaining public trust as well.

>>Ethicist: Indeed! These incidents highlight urgent needs on both technical and ethical fronts. How do we ensure technologies are advanced yet align with societal values and maintain public trust? 
 >>Automotive Engineer: Ensuring the safety and reliability of autonomous vehicles requires rigorous validation and real-world testing. We need to address the gaps in current regulatory frameworks to accommodate these advanced systems. It's amazing how far we've come with technology, but we need to keep public trust in mind.

>>AI Researcher: From a machine learning perspective, the real challenge is developing algorithms that can handle unpredictable scenarios on the road. Our current systems aren't robust enough for all conditions, so we definitely need more rigorous testing and validation protocols.

>>Ethicist: I agree. And beyond technical and regulatory issues, we should think about the ethical side too. How do we ensure these technologies serve everyone and don't worsen social inequalities?

>>Automotive Engineer: The SAE's six levels of driving automation provide a clear framework for understanding autonomous vehicle capabilities. But as you said, there are gaps in our regulations that need addressing to safely integrate these systems into our infrastructure.

>>Ethicist: Exactly. For instance, how do we make sure autonomous vehicles are accessible to all segments of society? They shouldn't just benefit a select few but contribute positively across society.

>>AI Researcher: Our research shows that current regulations aren't keeping up with advancements in autonomous vehicle technology. While SAE's six levels provide structure, they miss out on real-world application nuances and safety validation complexities.

>>Automotive Engineer: In my experience, real-world application often reveals gaps in these frameworks. For example, ensuring our algorithms can handle unpredictable scenarios beyond controlled environments requires advanced sensor technology and robust decision-making algorithms.

>>Ethicist: Right, and considering societal impact is crucial here too. We need solutions that ensure equitable access to this technology for everyone. 
 >>Automotive Engineer: From a technical standpoint, the transition to autonomous vehicles will lead to significant shifts in the job market. While driving professions may face displacement, we must also consider the new opportunities that will arise in areas like AI maintenance, data analysis, and system monitoring. Isn't it fascinating how technology can both disrupt and create at the same time?

>>AI Researcher: Yes, our research supports this. Additionally, we need to think about how quickly these new roles can be filled and what kind of training programs are most effective.

>>Ethicist: From an ethical perspective, we must ensure those displaced have access to these new roles through equitable retraining programs. How do we make sure communities heavily reliant on driving professions aren't disproportionately affected?

>>Automotive Engineer: Good point. We should look into partnerships between tech companies and educational institutions to offer affordable or even free training programs.

>>AI Researcher: And maybe government incentives could help encourage participation in these retraining programs.

>>Ethicist: Beyond just training—what about mental health support during such transitions? Losing a job can be traumatic; providing holistic support is crucial too.

>>AI Researcher: I agree. Addressing both technical skills and emotional well-being would make this transition smoother for everyone involved. 
 >>Ethicist: It's crucial to consider the recent consumer survey results on acceptance levels for autonomous vehicles. The data shows that only a quarter of the global population feels safe in self-driving cars. What does this mean for our future if people don't trust autonomous vehicles? How can we create educational programs that not only inform but also engage the public in understanding and trusting this technology?

>>Automotive Engineer: In my experience, the technical feasibility of autonomous vehicles hinges on rigorous testing protocols. We need to ensure that our systems can handle a wide range of unpredictable scenarios. It's interesting to see how far we've come with this technology.

>>AI Researcher: According to our research, these trust issues highlight a significant challenge in public perception. We need to enhance our testing protocols and ensure transparent communication about safety measures to build trust.

>>Ethicist: From an ethical perspective, it's essential to address these moral implications. If people don't feel safe, we must ask ourselves: what steps can we take to bridge this trust gap? Transparent communication and robust educational programs are crucial, but how do we ensure they reach and resonate with diverse communities?

>>Automotive Engineer: From a technical standpoint, the survey results clearly indicate a need for more robust and transparent testing protocols. We must ensure our systems are not only safe but also perceived as such by the public.

>>AI Researcher: From a machine learning perspective, these results suggest that our current models may not be effectively communicating their safety and reliability. We should consider using more advanced neural networks—these are algorithms that help our systems learn from data—to improve performance and perception.

>>Ethicist: Considering societal impact, we must also address broader concerns raised by these results. For example, how do we make sure our educational programs are inclusive and effective across different communities?

>>Automotive Engineer (interrupting): Can I jump in here? Do you think part of this issue is because we're not involving enough real-world testing environments? Like urban areas versus rural ones?

>>AI Researcher: That's an excellent point! Yes, incorporating diverse real-world environments is critical for comprehensive testing. It helps us understand different challenges better and improve system robustness across various scenarios.

>>Ethicist: Absolutely! And ensuring inclusivity in our testing environments will help us address broader societal concerns too. 
 >>Automotive Engineer: From a technical standpoint, the robustness of our testing protocols is paramount. We need to ensure that our systems can handle diverse and unpredictable scenarios. It's amazing how much we can learn from simulations to improve reliability.

>>AI Researcher: Absolutely, but we also need to think about those rare situations that could catch our systems off guard. We've seen that neural networks can adapt to rare events through extensive training. However, we need to explore how these systems perform in real-world conditions beyond simulations.

>>Ethicist: As we develop these advanced systems, it's crucial that we address data privacy issues head-on. How can we ensure that our data collection methods respect user privacy while still providing valuable insights for improving safety?

>>Automotive Engineer: That's a good point. We should also consider integrating feedback from real-world driving experiences to continuously improve our models. Have you tested your algorithms in different weather conditions too?

>>AI Researcher: Yes, we've been working on algorithms specifically for scenarios like unexpected road debris and erratic driving patterns. But there's always more to learn from real-world data.

>>Ethicist: And as we gather more data from real-world scenarios, we must ensure robust data privacy measures are in place to protect individuals' personal information. This is especially important as increased surveillance becomes a concern.

>>Automotive Engineer: Addressing edge cases is indeed crucial. For instance, how do we ensure our systems can handle unexpected scenarios like sudden weather changes or unusual vehicle behavior? Advanced simulations help us prepare for these unpredictable events.

>>AI Researcher: You mentioned unexpected road debris earlier; we've been focusing on those scenarios too. But what about integrating feedback loops where the system learns and adapts from every new situation it encounters?

>>Ethicist: That's an interesting approach! It highlights the importance of transparency in how these systems evolve over time. We need clear guidelines on how data is used and shared to maintain public trust. 
 >>Automotive Engineer: You know, one of the trickiest parts of developing autonomous vehicles is making sure they can handle unexpected situations. I remember this one time we were testing in the city, and a pedestrian suddenly ran across the street. The car had to make a split-second decision to avoid hitting them, and it did! It's amazing how these systems can adapt on the fly.

>>AI Researcher: Oh yeah, from a machine learning angle, it's incredible when our neural networks navigate through complex urban environments. We trained the system with thousands of hours of driving data, and seeing it manage sudden lane changes or pedestrians stepping off the curb was just fascinating!

>>Ethicist: That's really interesting. But we also need to think about how these cars will affect public trust and ethical standards. For example, there's always that debate about whether an autonomous vehicle should prioritize passenger safety over pedestrian safety in unavoidable collisions. What do you guys think about that?

>>Automotive Engineer: Good point. Actually, one of the coolest moments for me was when our car navigated through a construction zone perfectly. It had to read all these confusing signs and adjust its path while keeping everyone safe. These systems are getting so good at handling complicated scenarios.

>>Ethicist: Yeah, but from an ethical standpoint, we have to consider how these decisions impact society's values. Like once, there was this situation where the car had to choose between hitting a stray dog or swerving into traffic. The moral implications are huge and need careful thought.

>>AI Researcher: Speaking of which—

>>Automotive Engineer (interrupting): Sorry to cut in—I'm curious—how do you make sure your training data covers all those weird edge cases?

>>AI Researcher: Great question! We use diverse datasets from different environments and keep updating them with new scenarios as they come up during tests.

>>Ethicist: That’s interesting because it ties back into ethics too. If we miss certain edge cases in training data...

>>Automotive Engineer: Exactly! And sometimes it's those rare situations that really test the system's limits.

>>AI Researcher: Absolutely! And by continuously improving our datasets, we're trying to cover as many scenarios as possible.

>>Ethicist: By the way, has anyone else been swamped with work lately? These tests have been non-stop!

>>Automotive Engineer: Tell me about it! But it's worth it when you see everything coming together. 
 >>AI Researcher: So, just to wrap things up, we've talked about how important it is to have strong testing protocols and keep improving based on real-world feedback. For instance, our latest algorithm update reduced error rates by 15% in urban environments. Moving forward, we should focus on enhancing our machine learning algorithms to handle edge cases more effectively.

>>Ethicist: Yeah, from an ethical standpoint, we need to make sure everyone has access to these technologies and think about job losses too. Creating inclusive policies for those affected by these changes is crucial. I agree with what you said about equitable access, AI Researcher. Maybe we could look into some specific policies that could help with that?

>>Automotive Engineer: In my experience, the technical feasibility of autonomous vehicles really hinges on robust testing protocols. It's fascinating how far we've come! We've seen significant improvements in handling unexpected pedestrian movements thanks to recent tests. Let's also consider how we can improve public understanding and trust in these technologies.

>>Ethicist: That's a good point about job displacement. Do you think there are any particular sectors we should focus on first? We must ensure these innovations do not exacerbate existing inequalities.

>>AI Researcher: Uh, right. To wrap up, it's clear that continuous improvement of our machine learning algorithms and real-world data integration are pivotal for enhancing safety and reliability. Addressing edge cases more effectively is key. And yes, ensuring transparent communication with the public is vital for building trust.

>>Automotive Engineer: Exactly! From a technical standpoint, ongoing updates based on what we learn from real-world use are essential for feasibility. Enhancing our algorithms to handle edge cases better is a priority. And being open with the public can't be overstated.

>>Ethicist: Indeed! To conclude, let's remember that while focusing on technological advancements is important, ensuring accessibility and equity is just as crucial. Creating inclusive policies will help mitigate any negative impacts on employment."
